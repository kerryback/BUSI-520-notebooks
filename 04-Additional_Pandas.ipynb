{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "41deca97",
      "metadata": {},
      "source": [
        "# More Pandas\n",
        "\n",
        "### BUSI 520 - Python for Business Research\n",
        "### Kerry Back, JGSB, Rice University"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fbf5701",
      "metadata": {},
      "source": [
        "### Sorting, ranking, and quantiles\n",
        "\n",
        "* sort with **.sort_values(by=...)**\n",
        "* calculate ranks of a data column with **.rank()**\n",
        "  * ascending=True is default but can be changed with ascending=False\n",
        "  * how to break ties? method='average' is default but can use, e.g., method='first'\n",
        "* cut into quantiles with pd.qcut\n",
        "  * first argument is column\n",
        "  * second argument is # of groups (e.g., 5 = quintiles)\n",
        "  * specify labels=... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "d0549261",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wage</th>\n",
              "      <th>educ</th>\n",
              "      <th>exper</th>\n",
              "      <th>tenure</th>\n",
              "      <th>nonwhite</th>\n",
              "      <th>female</th>\n",
              "      <th>married</th>\n",
              "      <th>numdep</th>\n",
              "      <th>smsa</th>\n",
              "      <th>northcen</th>\n",
              "      <th>...</th>\n",
              "      <th>trcommpu</th>\n",
              "      <th>trade</th>\n",
              "      <th>services</th>\n",
              "      <th>profserv</th>\n",
              "      <th>profocc</th>\n",
              "      <th>clerocc</th>\n",
              "      <th>servocc</th>\n",
              "      <th>lwage</th>\n",
              "      <th>expersq</th>\n",
              "      <th>tenursq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.10</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.131402</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.24</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.175573</td>\n",
              "      <td>484</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.00</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.00</td>\n",
              "      <td>8</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1936</td>\n",
              "      <td>784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.30</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.667707</td>\n",
              "      <td>49</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   wage  educ  exper  tenure  nonwhite  female  married  numdep  smsa  \\\n",
              "0  3.10    11      2       0         0       1        0       2     1   \n",
              "1  3.24    12     22       2         0       1        1       3     1   \n",
              "2  3.00    11      2       0         0       0        0       2     0   \n",
              "3  6.00     8     44      28         0       0        1       0     1   \n",
              "4  5.30    12      7       2         0       0        1       1     0   \n",
              "\n",
              "   northcen  ...  trcommpu  trade  services  profserv  profocc  clerocc  \\\n",
              "0         0  ...         0      0         0         0        0        0   \n",
              "1         0  ...         0      0         1         0        0        0   \n",
              "2         0  ...         0      1         0         0        0        0   \n",
              "3         0  ...         0      0         0         0        0        1   \n",
              "4         0  ...         0      0         0         0        0        0   \n",
              "\n",
              "   servocc     lwage  expersq  tenursq  \n",
              "0        0  1.131402        4        0  \n",
              "1        1  1.175573      484        4  \n",
              "2        0  1.098612        4        0  \n",
              "3        0  1.791759     1936      784  \n",
              "4        0  1.667707       49        4  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_stata('WAGE1.dta')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "e2563ca2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wage</th>\n",
              "      <th>educ</th>\n",
              "      <th>exper</th>\n",
              "      <th>tenure</th>\n",
              "      <th>nonwhite</th>\n",
              "      <th>female</th>\n",
              "      <th>married</th>\n",
              "      <th>numdep</th>\n",
              "      <th>smsa</th>\n",
              "      <th>northcen</th>\n",
              "      <th>...</th>\n",
              "      <th>trcommpu</th>\n",
              "      <th>trade</th>\n",
              "      <th>services</th>\n",
              "      <th>profserv</th>\n",
              "      <th>profocc</th>\n",
              "      <th>clerocc</th>\n",
              "      <th>servocc</th>\n",
              "      <th>lwage</th>\n",
              "      <th>expersq</th>\n",
              "      <th>tenursq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>24.980000</td>\n",
              "      <td>18</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.218076</td>\n",
              "      <td>841</td>\n",
              "      <td>625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>22.860001</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.129389</td>\n",
              "      <td>256</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>22.200001</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.100092</td>\n",
              "      <td>961</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>21.860001</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.084659</td>\n",
              "      <td>576</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>21.629999</td>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.074081</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          wage  educ  exper  tenure  nonwhite  female  married  numdep  smsa  \\\n",
              "111  24.980000    18     29      25         0       0        1       0     1   \n",
              "228  22.860001    16     16       7         0       0        1       2     1   \n",
              "14   22.200001    12     31      15         0       0        1       1     1   \n",
              "185  21.860001    12     24      16         0       0        1       3     1   \n",
              "58   21.629999    18      8       8         0       1        0       0     1   \n",
              "\n",
              "     northcen  ...  trcommpu  trade  services  profserv  profocc  clerocc  \\\n",
              "111         0  ...         0      0         0         0        1        0   \n",
              "228         0  ...         0      0         0         0        1        0   \n",
              "14          0  ...         0      0         0         0        1        0   \n",
              "185         1  ...         0      1         0         0        1        0   \n",
              "58          0  ...         0      0         0         1        1        0   \n",
              "\n",
              "     servocc     lwage  expersq  tenursq  \n",
              "111        0  3.218076      841      625  \n",
              "228        0  3.129389      256       49  \n",
              "14         0  3.100092      961      225  \n",
              "185        0  3.084659      576      256  \n",
              "58         0  3.074081       64       64  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values('wage', ascending=False).head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "c1b4f7f5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exper</th>\n",
              "      <th>exper_grp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   exper exper_grp\n",
              "0      2         1\n",
              "1     22         4\n",
              "2      2         1\n",
              "3     44         5\n",
              "4      7         2"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['exper_grp'] = pd.qcut(df.exper, 5, labels=range(1, 6))\n",
        "df[['exper', 'exper_grp']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "8f79cd8d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "exper_grp\n",
              "1    4.257679\n",
              "2    6.037407\n",
              "3    6.279038\n",
              "4    7.512500\n",
              "5    5.491123\n",
              "Name: wage, dtype: float32"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby('exper_grp').wage.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8169d3e",
      "metadata": {},
      "source": [
        "### Question\n",
        "\n",
        "What will the following code create?\n",
        "\n",
        "    df.groupby(['female', 'exper_grp']).wage.mean().unstack('female').round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3adec527",
      "metadata": {},
      "source": [
        "What about this?\n",
        "\n",
        "     df.groupby(['female', 'exper_grp']).wage.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf9d71d",
      "metadata": {},
      "source": [
        "And this?\n",
        "\n",
        "    df.female = df.female.map(\n",
        "        {\n",
        "            0: 'male',\n",
        "            1: 'female'\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "8bb17697",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['wage', 'educ', 'exper', 'tenure', 'nonwhite', 'female', 'married',\n",
              "       'numdep', 'smsa', 'northcen', 'south', 'west', 'construc', 'ndurman',\n",
              "       'trcommpu', 'trade', 'services', 'profserv', 'profocc', 'clerocc',\n",
              "       'servocc', 'lwage', 'expersq', 'tenursq', 'exper_grp'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96330a4a",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "From the dummy variables 'northcen', 'south', 'west, create a column called 'area' that has values\n",
        "\n",
        "* 'northcen' if northcen==1\n",
        "* 'south' if south==1\n",
        "* 'west' if west==1\n",
        "* 'northeast' if northcen==south==west==0.\n",
        "\n",
        "Compute the average wage by area and white/nonwhite."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd2a5c7f-1212-4a08-bab4-f54c7db8820b",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "### Pandas DataReader Module\n",
        "\n",
        "The `pandas-datareader` module provides a convenient way to fetch financial and economic data from various online sources directly into a pandas DataFrame. One of the popular sources it supports is the Federal Reserve Economic Data (FRED) provided by the Federal Reserve Bank of St. Louis.\n",
        "\n",
        "To use `pandas-datareader`, you'll first need to install it using `pip`:\n",
        "\n",
        "```python\n",
        "!pip install pandas-datareader\n",
        "```\n",
        "\n",
        "Once installed, you can fetch data from various sources, including FRED.\n",
        "\n",
        "#### Fetching Data from FRED using Pandas DataReader\n",
        "\n",
        "Let's see some examples of fetching data from FRED using `pandas-datareader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "9e5a36a8-e7ec-45c0-ae1a-5e99ffcf163c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-26T15:01:56.870377+00:00",
          "start_time": "2023-08-26T15:01:56.338552+00:00"
        },
        "datalink": {
          "3745d1a8-aefd-4538-9b73-e77a600884e5": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": false,
              "orig_num_cols": 1,
              "orig_num_rows": 5,
              "orig_size_bytes": 80,
              "truncated_num_cols": 1,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 80,
              "truncated_string_columns": []
            },
            "display_id": "3745d1a8-aefd-4538-9b73-e77a600884e5",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-08-26T15:01:56.700967",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_66f360a0035343acba3057ef5b1017ad"
          }
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DCOILWTICO</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1986-01-02</th>\n",
              "      <td>25.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-01-03</th>\n",
              "      <td>26.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-01-06</th>\n",
              "      <td>26.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-01-07</th>\n",
              "      <td>25.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-01-08</th>\n",
              "      <td>25.87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            DCOILWTICO\n",
              "DATE                  \n",
              "1986-01-02       25.56\n",
              "1986-01-03       26.00\n",
              "1986-01-06       26.53\n",
              "1986-01-07       25.85\n",
              "1986-01-08       25.87"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas_datareader as pdr\n",
        "\n",
        "# Define the start and end date\n",
        "start = '1970-01-01'\n",
        "end = '2023-01-01'\n",
        "\n",
        "# Fetching WTI crude oil prices from FRED\n",
        "oil = pdr.DataReader('DCOILWTICO', 'fred', start, end)\n",
        "oil.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "2e870520",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 9652 entries, 1986-01-02 to 2022-12-30\n",
            "Data columns (total 1 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   DCOILWTICO  9323 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 150.8 KB\n"
          ]
        }
      ],
      "source": [
        "oil.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bacda6d0",
      "metadata": {},
      "source": [
        "### Converting Strings to Datetime Objects\n",
        "\n",
        "To convert a string to a datetime object, we use the `strptime` method of the `datetime` class. The `strptime` method requires two arguments:\n",
        "\n",
        "1. The string representing the date and/or time.\n",
        "2. The format code representing the expected format of the string.\n",
        "\n",
        "Let's see some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "4ad444d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-26 00:00:00\n",
            "2023-08-26 00:00:00\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Example 1: Convert a string in the format 'YYYY-MM-DD' to a datetime object\n",
        "date_string1 = '2023-08-26'\n",
        "date_object1 = datetime.strptime(date_string1, '%Y-%m-%d')\n",
        "print(date_object1)\n",
        "\n",
        "# Example 2: Convert a string in the format 'DD/MM/YYYY' to a datetime object\n",
        "date_string2 = '26/08/2023'\n",
        "date_object2 = datetime.strptime(date_string2, '%d/%m/%Y')\n",
        "print(date_object2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f58151",
      "metadata": {},
      "source": [
        "### Datetime Attributes and Methods\n",
        "\n",
        "Try the following:\n",
        "\n",
        "    today = datetime.today()\n",
        "    today.year\n",
        "    today.month\n",
        "    today.day\n",
        "    today.weekday()\n",
        "    another_day = datetime.strptime('2022-09-06', '%Y-%m-%d')\n",
        "    (today - another_day).days"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26309057",
      "metadata": {},
      "source": [
        "### Converting Datetime Objects to Strings\n",
        "\n",
        "To convert a datetime object back to a string, we use the `strftime` method of the `datetime` class. \n",
        "\n",
        "The `strftime` method requires one argument: the format code representing the desired format of the output string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "81bdec24",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-26\n",
            "26/08/2023\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Convert a datetime object to a string in the format 'YYYY-MM-DD'\n",
        "formatted_date1 = date_object1.strftime('%Y-%m-%d')\n",
        "print(formatted_date1)\n",
        "\n",
        "# Example 2: Convert a datetime object to a string in the format 'DD/MM/YYYY'\n",
        "formatted_date2 = date_object2.strftime('%d/%m/%Y')\n",
        "print(formatted_date2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "891d166d",
      "metadata": {},
      "source": [
        "### Converting from Datetime to String and vice versa in Pandas\n",
        "\n",
        "* Use **astype(str)** to convert from datetime to string.\n",
        "* Use the pd.to_datetime function to convert from string to datetime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "1541b317",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['1986-01-02', '1986-01-03', '1986-01-06', '1986-01-07', '1986-01-08',\n",
            "       '1986-01-09', '1986-01-10', '1986-01-13', '1986-01-14', '1986-01-15',\n",
            "       ...\n",
            "       '2022-12-19', '2022-12-20', '2022-12-21', '2022-12-22', '2022-12-23',\n",
            "       '2022-12-26', '2022-12-27', '2022-12-28', '2022-12-29', '2022-12-30'],\n",
            "      dtype='object', name='DATE', length=9652)\n"
          ]
        }
      ],
      "source": [
        "datetime_index = oil.index\n",
        "string_index = datetime_index.astype(str)\n",
        "datetime_index_again = pd.to_datetime(string_index)\n",
        "\n",
        "print(string_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "69fe0085",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatetimeIndex(['1986-01-02', '1986-01-03', '1986-01-06', '1986-01-07',\n",
            "               '1986-01-08', '1986-01-09', '1986-01-10', '1986-01-13',\n",
            "               '1986-01-14', '1986-01-15',\n",
            "               ...\n",
            "               '2022-12-19', '2022-12-20', '2022-12-21', '2022-12-22',\n",
            "               '2022-12-23', '2022-12-26', '2022-12-27', '2022-12-28',\n",
            "               '2022-12-29', '2022-12-30'],\n",
            "              dtype='datetime64[ns]', name='DATE', length=9652, freq=None)\n"
          ]
        }
      ],
      "source": [
        "print(datetime_index_again)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e45367",
      "metadata": {},
      "source": [
        "### Fama-French data\n",
        "\n",
        "We can get the datasets in Ken French's data library with the pandas datareader.  We can start by finding the names of the datasets as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "57743223",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['F-F_Research_Data_Factors',\n",
              " 'F-F_Research_Data_Factors_weekly',\n",
              " 'F-F_Research_Data_Factors_daily',\n",
              " 'F-F_Research_Data_5_Factors_2x3',\n",
              " 'F-F_Research_Data_5_Factors_2x3_daily',\n",
              " 'Portfolios_Formed_on_ME',\n",
              " 'Portfolios_Formed_on_ME_Wout_Div',\n",
              " 'Portfolios_Formed_on_ME_Daily',\n",
              " 'Portfolios_Formed_on_BE-ME',\n",
              " 'Portfolios_Formed_on_BE-ME_Wout_Div',\n",
              " 'Portfolios_Formed_on_BE-ME_Daily',\n",
              " 'Portfolios_Formed_on_OP',\n",
              " 'Portfolios_Formed_on_OP_Wout_Div',\n",
              " 'Portfolios_Formed_on_OP_Daily',\n",
              " 'Portfolios_Formed_on_INV',\n",
              " 'Portfolios_Formed_on_INV_Wout_Div',\n",
              " 'Portfolios_Formed_on_INV_Daily',\n",
              " '6_Portfolios_2x3',\n",
              " '6_Portfolios_2x3_Wout_Div',\n",
              " '6_Portfolios_2x3_weekly',\n",
              " '6_Portfolios_2x3_daily',\n",
              " '25_Portfolios_5x5',\n",
              " '25_Portfolios_5x5_Wout_Div',\n",
              " '25_Portfolios_5x5_Daily',\n",
              " '100_Portfolios_10x10',\n",
              " '100_Portfolios_10x10_Wout_Div',\n",
              " '100_Portfolios_10x10_Daily',\n",
              " '6_Portfolios_ME_OP_2x3',\n",
              " '6_Portfolios_ME_OP_2x3_Wout_Div',\n",
              " '6_Portfolios_ME_OP_2x3_daily',\n",
              " '25_Portfolios_ME_OP_5x5',\n",
              " '25_Portfolios_ME_OP_5x5_Wout_Div',\n",
              " '25_Portfolios_ME_OP_5x5_daily',\n",
              " '100_Portfolios_ME_OP_10x10',\n",
              " '100_Portfolios_10x10_ME_OP_Wout_Div',\n",
              " '100_Portfolios_ME_OP_10x10_daily',\n",
              " '6_Portfolios_ME_INV_2x3',\n",
              " '6_Portfolios_ME_INV_2x3_Wout_Div',\n",
              " '6_Portfolios_ME_INV_2x3_daily',\n",
              " '25_Portfolios_ME_INV_5x5',\n",
              " '25_Portfolios_ME_INV_5x5_Wout_Div',\n",
              " '25_Portfolios_ME_INV_5x5_daily',\n",
              " '100_Portfolios_ME_INV_10x10',\n",
              " '100_Portfolios_10x10_ME_INV_Wout_Div',\n",
              " '100_Portfolios_ME_INV_10x10_daily',\n",
              " '25_Portfolios_BEME_OP_5x5',\n",
              " '25_Portfolios_BEME_OP_5x5_Wout_Div',\n",
              " '25_Portfolios_BEME_OP_5x5_daily',\n",
              " '25_Portfolios_BEME_INV_5x5',\n",
              " '25_Portfolios_BEME_INV_5x5_Wout_Div',\n",
              " '25_Portfolios_BEME_INV_5x5_daily',\n",
              " '25_Portfolios_OP_INV_5x5',\n",
              " '25_Portfolios_OP_INV_5x5_Wout_Div',\n",
              " '25_Portfolios_OP_INV_5x5_daily',\n",
              " '32_Portfolios_ME_BEME_OP_2x4x4',\n",
              " '32_Portfolios_ME_BEME_OP_2x4x4_Wout_Div',\n",
              " '32_Portfolios_ME_BEME_INV_2x4x4',\n",
              " '32_Portfolios_ME_BEME_INV_2x4x4_Wout_Div',\n",
              " '32_Portfolios_ME_OP_INV_2x4x4',\n",
              " '32_Portfolios_ME_OP_INV_2x4x4_Wout_Div',\n",
              " 'Portfolios_Formed_on_E-P',\n",
              " 'Portfolios_Formed_on_E-P_Wout_Div',\n",
              " 'Portfolios_Formed_on_CF-P',\n",
              " 'Portfolios_Formed_on_CF-P_Wout_Div',\n",
              " 'Portfolios_Formed_on_D-P',\n",
              " 'Portfolios_Formed_on_D-P_Wout_Div',\n",
              " '6_Portfolios_ME_EP_2x3',\n",
              " '6_Portfolios_ME_EP_2x3_Wout_Div',\n",
              " '6_Portfolios_ME_CFP_2x3',\n",
              " '6_Portfolios_ME_CFP_2x3_Wout_Div',\n",
              " '6_Portfolios_ME_DP_2x3',\n",
              " '6_Portfolios_ME_DP_2x3_Wout_Div',\n",
              " 'F-F_Momentum_Factor',\n",
              " 'F-F_Momentum_Factor_daily',\n",
              " '6_Portfolios_ME_Prior_12_2',\n",
              " '6_Portfolios_ME_Prior_12_2_Daily',\n",
              " '25_Portfolios_ME_Prior_12_2',\n",
              " '25_Portfolios_ME_Prior_12_2_Daily',\n",
              " '10_Portfolios_Prior_12_2',\n",
              " '10_Portfolios_Prior_12_2_Daily',\n",
              " 'F-F_ST_Reversal_Factor',\n",
              " 'F-F_ST_Reversal_Factor_daily',\n",
              " '6_Portfolios_ME_Prior_1_0',\n",
              " '6_Portfolios_ME_Prior_1_0_Daily',\n",
              " '25_Portfolios_ME_Prior_1_0',\n",
              " '25_Portfolios_ME_Prior_1_0_Daily',\n",
              " '10_Portfolios_Prior_1_0',\n",
              " '10_Portfolios_Prior_1_0_Daily',\n",
              " 'F-F_LT_Reversal_Factor',\n",
              " 'F-F_LT_Reversal_Factor_daily',\n",
              " '6_Portfolios_ME_Prior_60_13',\n",
              " '6_Portfolios_ME_Prior_60_13_Daily',\n",
              " '25_Portfolios_ME_Prior_60_13',\n",
              " '25_Portfolios_ME_Prior_60_13_Daily',\n",
              " '10_Portfolios_Prior_60_13',\n",
              " '10_Portfolios_Prior_60_13_Daily',\n",
              " 'Portfolios_Formed_on_AC',\n",
              " '25_Portfolios_ME_AC_5x5',\n",
              " 'Portfolios_Formed_on_BETA',\n",
              " '25_Portfolios_ME_BETA_5x5',\n",
              " 'Portfolios_Formed_on_NI',\n",
              " '25_Portfolios_ME_NI_5x5',\n",
              " 'Portfolios_Formed_on_VAR',\n",
              " '25_Portfolios_ME_VAR_5x5',\n",
              " 'Portfolios_Formed_on_RESVAR',\n",
              " '25_Portfolios_ME_RESVAR_5x5',\n",
              " '5_Industry_Portfolios',\n",
              " '5_Industry_Portfolios_Wout_Div',\n",
              " '5_Industry_Portfolios_daily',\n",
              " '10_Industry_Portfolios',\n",
              " '10_Industry_Portfolios_Wout_Div',\n",
              " '10_Industry_Portfolios_daily',\n",
              " '12_Industry_Portfolios',\n",
              " '12_Industry_Portfolios_Wout_Div',\n",
              " '12_Industry_Portfolios_daily',\n",
              " '17_Industry_Portfolios',\n",
              " '17_Industry_Portfolios_Wout_Div',\n",
              " '17_Industry_Portfolios_daily',\n",
              " '30_Industry_Portfolios',\n",
              " '30_Industry_Portfolios_Wout_Div',\n",
              " '30_Industry_Portfolios_daily',\n",
              " '38_Industry_Portfolios',\n",
              " '38_Industry_Portfolios_Wout_Div',\n",
              " '38_Industry_Portfolios_daily',\n",
              " '48_Industry_Portfolios',\n",
              " '48_Industry_Portfolios_Wout_Div',\n",
              " '48_Industry_Portfolios_daily',\n",
              " '49_Industry_Portfolios',\n",
              " '49_Industry_Portfolios_Wout_Div',\n",
              " '49_Industry_Portfolios_daily',\n",
              " 'ME_Breakpoints',\n",
              " 'BE-ME_Breakpoints',\n",
              " 'OP_Breakpoints',\n",
              " 'INV_Breakpoints',\n",
              " 'E-P_Breakpoints',\n",
              " 'CF-P_Breakpoints',\n",
              " 'D-P_Breakpoints',\n",
              " 'Prior_2-12_Breakpoints',\n",
              " 'Developed_3_Factors',\n",
              " 'Developed_3_Factors_Daily',\n",
              " 'Developed_ex_US_3_Factors',\n",
              " 'Developed_ex_US_3_Factors_Daily',\n",
              " 'Europe_3_Factors',\n",
              " 'Europe_3_Factors_Daily',\n",
              " 'Japan_3_Factors',\n",
              " 'Japan_3_Factors_Daily',\n",
              " 'Asia_Pacific_ex_Japan_3_Factors',\n",
              " 'Asia_Pacific_ex_Japan_3_Factors_Daily',\n",
              " 'North_America_3_Factors',\n",
              " 'North_America_3_Factors_Daily',\n",
              " 'Developed_5_Factors',\n",
              " 'Developed_5_Factors_Daily',\n",
              " 'Developed_ex_US_5_Factors',\n",
              " 'Developed_ex_US_5_Factors_Daily',\n",
              " 'Europe_5_Factors',\n",
              " 'Europe_5_Factors_Daily',\n",
              " 'Japan_5_Factors',\n",
              " 'Japan_5_Factors_Daily',\n",
              " 'Asia_Pacific_ex_Japan_5_Factors',\n",
              " 'Asia_Pacific_ex_Japan_5_Factors_Daily',\n",
              " 'North_America_5_Factors',\n",
              " 'North_America_5_Factors_Daily',\n",
              " 'Developed_Mom_Factor',\n",
              " 'Developed_Mom_Factor_Daily',\n",
              " 'Developed_ex_US_Mom_Factor',\n",
              " 'Developed_ex_US_Mom_Factor_Daily',\n",
              " 'Europe_Mom_Factor',\n",
              " 'Europe_Mom_Factor_Daily',\n",
              " 'Japan_Mom_Factor',\n",
              " 'Japan_Mom_Factor_Daily',\n",
              " 'Asia_Pacific_ex_Japan_MOM_Factor',\n",
              " 'Asia_Pacific_ex_Japan_MOM_Factor_Daily',\n",
              " 'North_America_Mom_Factor',\n",
              " 'North_America_Mom_Factor_Daily',\n",
              " 'Developed_6_Portfolios_ME_BE-ME',\n",
              " 'Developed_6_Portfolios_ME_BE-ME_daily',\n",
              " 'Developed_ex_US_6_Portfolios_ME_BE-ME',\n",
              " 'Developed_ex_US_6_Portfolios_ME_BE-ME_daily',\n",
              " 'Europe_6_Portfolios_ME_BE-ME',\n",
              " 'Europe_6_Portfolios_ME_BE-ME_daily',\n",
              " 'Japan_6_Portfolios_ME_BE-ME',\n",
              " 'Japan_6_Portfolios_ME_BE-ME_daily',\n",
              " 'Asia_Pacific_ex_Japan_6_Portfolios_ME_BE-ME',\n",
              " 'Asia_Pacific_ex_Japan_6_Portfolios_ME_BE-ME_daily',\n",
              " 'North_America_6_Portfolios_ME_BE-ME',\n",
              " 'North_America_6_Portfolios_ME_BE-ME_daily',\n",
              " 'Developed_25_Portfolios_ME_BE-ME',\n",
              " 'Developed_25_Portfolios_ME_BE-ME_daily',\n",
              " 'Developed_ex_US_25_Portfolios_ME_BE-ME',\n",
              " 'Developed_ex_US_25_Portfolios_ME_BE-ME_daily',\n",
              " 'Europe_25_Portfolios_ME_BE-ME',\n",
              " 'Europe_25_Portfolios_ME_BE-ME_daily',\n",
              " 'Japan_25_Portfolios_ME_BE-ME',\n",
              " 'Japan_25_Portfolios_ME_BE-ME_daily',\n",
              " 'Asia_Pacific_ex_Japan_25_Portfolios_ME_BE-ME',\n",
              " 'Asia_Pacific_ex_Japan_25_Portfolios_ME_BE-ME_daily',\n",
              " 'North_America_25_Portfolios_ME_BE-ME',\n",
              " 'North_America_25_Portfolios_ME_BE-ME_daily',\n",
              " 'Developed_6_Portfolios_ME_OP',\n",
              " 'Developed_6_Portfolios_ME_OP_Daily',\n",
              " 'Developed_ex_US_6_Portfolios_ME_OP',\n",
              " 'Developed_ex_US_6_Portfolios_ME_OP_Daily',\n",
              " 'Europe_6_Portfolios_ME_OP',\n",
              " 'Europe_6_Portfolios_ME_OP_Daily',\n",
              " 'Japan_6_Portfolios_ME_OP',\n",
              " 'Japan_6_Portfolios_ME_OP_Daily',\n",
              " 'Asia_Pacific_ex_Japan_6_Portfolios_ME_OP',\n",
              " 'Asia_Pacific_ex_Japan_6_Portfolios_ME_OP_Daily',\n",
              " 'North_America_6_Portfolios_ME_OP',\n",
              " 'North_America_6_Portfolios_ME_OP_Daily',\n",
              " 'Developed_25_Portfolios_ME_OP',\n",
              " 'Developed_25_Portfolios_ME_OP_Daily',\n",
              " 'Developed_ex_US_25_Portfolios_ME_OP',\n",
              " 'Developed_ex_US_25_Portfolios_ME_OP_Daily',\n",
              " 'Europe_25_Portfolios_ME_OP',\n",
              " 'Europe_25_Portfolios_ME_OP_Daily',\n",
              " 'Japan_25_Portfolios_ME_OP',\n",
              " 'Japan_25_Portfolios_ME_OP_Daily',\n",
              " 'Asia_Pacific_ex_Japan_25_Portfolios_ME_OP',\n",
              " 'Asia_Pacific_ex_Japan_25_Portfolios_ME_OP_Daily',\n",
              " 'North_America_25_Portfolios_ME_OP',\n",
              " 'North_America_25_Portfolios_ME_OP_Daily',\n",
              " 'Developed_6_Portfolios_ME_INV',\n",
              " 'Developed_6_Portfolios_ME_INV_Daily',\n",
              " 'Developed_ex_US_6_Portfolios_ME_INV',\n",
              " 'Developed_ex_US_6_Portfolios_ME_INV_Daily',\n",
              " 'Europe_6_Portfolios_ME_INV',\n",
              " 'Europe_6_Portfolios_ME_INV_Daily',\n",
              " 'Japan_6_Portfolios_ME_INV',\n",
              " 'Japan_6_Portfolios_ME_INV_Daily',\n",
              " 'Asia_Pacific_ex_Japan_6_Portfolios_ME_INV',\n",
              " 'Asia_Pacific_ex_Japan_6_Portfolios_ME_INV_Daily',\n",
              " 'North_America_6_Portfolios_ME_INV',\n",
              " 'North_America_6_Portfolios_ME_INV_Daily',\n",
              " 'Developed_25_Portfolios_ME_INV',\n",
              " 'Developed_25_Portfolios_ME_INV_Daily',\n",
              " 'Developed_ex_US_25_Portfolios_ME_INV',\n",
              " 'Developed_ex_US_25_Portfolios_ME_INV_Daily',\n",
              " 'Europe_25_Portfolios_ME_INV',\n",
              " 'Europe_25_Portfolios_ME_INV_Daily',\n",
              " 'Japan_25_Portfolios_ME_INV',\n",
              " 'Japan_25_Portfolios_ME_INV_Daily',\n",
              " 'Asia_Pacific_ex_Japan_25_Portfolios_ME_INV',\n",
              " 'Asia_Pacific_ex_Japan_25_Portfolios_ME_INV_Daily',\n",
              " 'North_America_25_Portfolios_ME_INV',\n",
              " 'North_America_25_Portfolios_ME_INV_Daily',\n",
              " 'Developed_6_Portfolios_ME_Prior_12_2',\n",
              " 'Developed_6_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Developed_ex_US_6_Portfolios_ME_Prior_12_2',\n",
              " 'Developed_ex_US_6_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Europe_6_Portfolios_ME_Prior_12_2',\n",
              " 'Europe_6_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Japan_6_Portfolios_ME_Prior_12_2',\n",
              " 'Japan_6_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Asia_Pacific_ex_Japan_6_Portfolios_ME_Prior_12_2',\n",
              " 'Asia_Pacific_ex_Japan_6_Portfolios_ME_Prior_250_20_daily',\n",
              " 'North_America_6_Portfolios_ME_Prior_12_2',\n",
              " 'North_America_6_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Developed_25_Portfolios_ME_Prior_12_2',\n",
              " 'Developed_25_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Developed_ex_US_25_Portfolios_ME_Prior_12_2',\n",
              " 'Developed_ex_US_25_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Europe_25_Portfolios_ME_Prior_12_2',\n",
              " 'Europe_25_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Japan_25_Portfolios_ME_Prior_12_2',\n",
              " 'Japan_25_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Asia_Pacific_ex_Japan_25_Portfolios_ME_Prior_12_2',\n",
              " 'Asia_Pacific_ex_Japan_25_Portfolios_ME_Prior_250_20_daily',\n",
              " 'North_America_25_Portfolios_ME_Prior_12_2',\n",
              " 'North_America_25_Portfolios_ME_Prior_250_20_daily',\n",
              " 'Developed_32_Portfolios_ME_BE-ME_OP_2x4x4',\n",
              " 'Developed_ex_US_32_Portfolios_ME_BE-ME_OP_2x4x4',\n",
              " 'Europe_32_Portfolios_ME_BE-ME_OP_2x4x4',\n",
              " 'Japan_32_Portfolios_ME_BE-ME_OP_2x4x4',\n",
              " 'Asia_Pacific_ex_Japan_32_Portfolios_ME_BE-ME_OP_2x4x4',\n",
              " 'North_America_32_Portfolios_ME_BE-ME_OP_2x4x4',\n",
              " 'Developed_32_Portfolios_ME_BE-ME_INV(TA)_2x4x4',\n",
              " 'Developed_ex_US_32_Portfolios_ME_BE-ME_INV(TA)_2x4x4',\n",
              " 'Europe_32_Portfolios_ME_BE-ME_INV(TA)_2x4x4',\n",
              " 'Japan_32_Portfolios_ME_BE-ME_INV(TA)_2x4x4',\n",
              " 'Asia_Pacific_ex_Japan_32_Portfolios_ME_BE-ME_INV(TA)_2x4x4',\n",
              " 'North_America_32_Portfolios_ME_BE-ME_INV(TA)_2x4x4',\n",
              " 'Developed_32_Portfolios_ME_INV(TA)_OP_2x4x4',\n",
              " 'Developed_ex_US_32_Portfolios_ME_INV(TA)_OP_2x4x4',\n",
              " 'Europe_32_Portfolios_ME_INV(TA)_OP_2x4x4',\n",
              " 'Japan_32_Portfolios_ME_INV(TA)_OP_2x4x4',\n",
              " 'Asia_Pacific_ex_Japan_32_Portfolios_ME_INV(TA)_OP_2x4x4',\n",
              " 'North_America_32_Portfolios_ME_INV(TA)_OP_2x4x4',\n",
              " 'Emerging_5_Factors',\n",
              " 'Emerging_MOM_Factor',\n",
              " 'Emerging_Markets_6_Portfolios_ME_BE-ME',\n",
              " 'Emerging_Markets_6_Portfolios_ME_OP',\n",
              " 'Emerging_Markets_6_Portfolios_ME_INV',\n",
              " 'Emerging_Markets_6_Portfolios_ME_Prior_12_2',\n",
              " 'Emerging_Markets_4_Portfolios_BE-ME_OP',\n",
              " 'Emerging_Markets_4_Portfolios_OP_INV',\n",
              " 'Emerging_Markets_4_Portfolios_BE-ME_INV']"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr.famafrench.get_available_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c24a483d",
      "metadata": {},
      "source": [
        "Pass a dataset name to the pdr DataReader with the code 'famafrench.'  As an example, we will get the three Fama-French factors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "id": "722e6f26",
      "metadata": {},
      "outputs": [],
      "source": [
        "ff = pdr.DataReader(\n",
        "    'F-F_Research_Data_Factors', \n",
        "    'famafrench', \n",
        "    start, \n",
        "    end\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27800bfe",
      "metadata": {},
      "source": [
        "Try the following:\n",
        "   \n",
        "    type(ff)\n",
        "    ff.keys()\n",
        "    ff['DESCR']\n",
        "    ff[0].head()\n",
        "    ff[0].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33a0f12c-3e05-470d-ba4d-8129144884bb",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "### Conversions of Period Format\n",
        "\n",
        "* Use **.astype(str)** to convert from period to string\n",
        "* To convert from period to datetime:\n",
        "  * Use **.to_timestamp()** for an index\n",
        "  * Use **.dt.to_timestamp()** for a series or column\n",
        "* To convert from datetime to period:\n",
        "  * use **.to_period()** for an index\n",
        "  * use **.dt.to_period()** for a series or column\n",
        "* To convert from string to period:\n",
        "  * convert to datetime first then to period\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef4c575",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "* Convert the index of ff[0] from period to datetime.\n",
        "* Convert it back to period.\n",
        "* Convert it from period to string.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fad8012",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "* Create a column of months in the oil dataframe (hint: convert datetime to period)\n",
        "* Compute the average oil price by month"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f173ba4d-b19d-41d4-afc1-a50f0c8c7f0e",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "### `shift`, `diff`, and `pct_change` \n",
        "\n",
        "Pandas provides several methods to perform operations on time series data. Three commonly used methods are `shift`, `diff`, and `pct_change`. Let's understand each of these methods using the GDP data we fetched earlier.\n",
        "\n",
        "#### 1. `shift` Method\n",
        "The `shift` method is used to shift the values of a series or dataframe by a specified number of periods. \n",
        "\n",
        "#### 2. `diff` Method\n",
        "The `diff` method calculates the difference of a series element compared with another element in the series (default is the element in the previous row). \n",
        "\n",
        "#### 3. `pct_change` Method\n",
        "The `pct_change` method computes the percentage change between the current and a prior element. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "id": "58f8959f-a3ab-423c-9ba3-0c4ac8e67aa6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-26T15:54:45.957528+00:00",
          "start_time": "2023-08-26T15:54:45.359677+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>lag</th>\n",
              "      <th>change</th>\n",
              "      <th>pct_change</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1986-01-02</th>\n",
              "      <td>25.56</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-01-03</th>\n",
              "      <td>26.00</td>\n",
              "      <td>25.56</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.017214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-01-06</th>\n",
              "      <td>26.53</td>\n",
              "      <td>26.00</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.020385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            price    lag  change  pct_change\n",
              "DATE                                        \n",
              "1986-01-02  25.56    NaN     NaN         NaN\n",
              "1986-01-03  26.00  25.56    0.44    0.017214\n",
              "1986-01-06  26.53  26.00    0.53    0.020385"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# change the name DCOILWTICO to price for convenience\n",
        "oil.columns = ['price']\n",
        "\n",
        "oil['lag'] = oil.price.shift()\n",
        "oil['change'] = oil.price.diff()\n",
        "oil['pct_change'] = oil.price.pct_change()\n",
        "\n",
        "oil.head(3)\n",
        "\n",
        "# how do we get rid of the row with NaNs?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56875361",
      "metadata": {},
      "source": [
        "### Cumsum and cumprod\n",
        "\n",
        "To cumulatively sum the elements of a series or dataframe, use the cumsum method.  To cumulatively multiply, use cumprod.  \n",
        "\n",
        "We can use cumprod to calculate a cumulative (compound) return."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "id": "b13506b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute the market return from Fama-French by adding the risk-free return back\n",
        "# and convert to decimals\n",
        "mkt = (ff_monthly['Mkt-RF'] + ff_monthly['RF']) / 100\n",
        "\n",
        "# compute compounded returns\n",
        "mkt_compound_ret = (1+mkt).cumprod() - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c41453ce",
      "metadata": {},
      "source": [
        "What will the following produce?\n",
        "\n",
        "    pd.concat((mkt, mkt_compound_ret), axis=1).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa5c6b1d",
      "metadata": {},
      "source": [
        "### Downsampling and upsampling\n",
        "\n",
        "Pandas provides methods for changing the frequency of the data.  If we want to compute the monthly percent change using the last day of the month, here is an easy way to do it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "id": "65281f32",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1986-01-31</th>\n",
              "      <td>18.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-02-28</th>\n",
              "      <td>13.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-03-31</th>\n",
              "      <td>10.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-04-30</th>\n",
              "      <td>13.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-05-31</th>\n",
              "      <td>14.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            price\n",
              "DATE             \n",
              "1986-01-31  18.95\n",
              "1986-02-28  13.23\n",
              "1986-03-31  10.25\n",
              "1986-04-30  13.38\n",
              "1986-05-31  14.30"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for clarity, use only the price column in the exercise\n",
        "oil = oil.drop(columns=['lag', 'change', 'pct_change'])\n",
        "\n",
        "# downsample to monthly\n",
        "oil_monthly = oil.resample('M').last()\n",
        "\n",
        "oil_monthly.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "id": "420d8ad5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>pct_change</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1986-01-31</th>\n",
              "      <td>18.95</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-02-28</th>\n",
              "      <td>13.23</td>\n",
              "      <td>-0.301847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-03-31</th>\n",
              "      <td>10.25</td>\n",
              "      <td>-0.225246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-04-30</th>\n",
              "      <td>13.38</td>\n",
              "      <td>0.305366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986-05-31</th>\n",
              "      <td>14.30</td>\n",
              "      <td>0.068759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            price  pct_change\n",
              "DATE                         \n",
              "1986-01-31  18.95         NaN\n",
              "1986-02-28  13.23   -0.301847\n",
              "1986-03-31  10.25   -0.225246\n",
              "1986-04-30  13.38    0.305366\n",
              "1986-05-31  14.30    0.068759"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# add monthly pct_change column\n",
        "oil_monthly['pct_change'] = oil_monthly.price.pct_change()\n",
        "oil_monthly.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7b78ee5",
      "metadata": {},
      "source": [
        "Try this:\n",
        "\n",
        "    oil.resample('M').price.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83999cca",
      "metadata": {},
      "source": [
        "And this:\n",
        "\n",
        "    oil_monthly.resample('D').ffill()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd61c18",
      "metadata": {},
      "source": [
        "And this:\n",
        "    \n",
        "    days = pd.date_range(start='1986-01-31', end='2022-12-31')\n",
        "    oil_monthly.reindex(days).ffill()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3919a739",
      "metadata": {},
      "source": [
        "### Rolling and expanding objects\n",
        "\n",
        "To calculate an aggregate over a rolling window, create a rolling object and then apply the aggregation method, which can be user defined, using the apply method.\n",
        "\n",
        "We can do the same over an expanding window by creating an expanding object."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc474d12",
      "metadata": {},
      "source": [
        "What do these create?\n",
        "\n",
        "    oil.price.rolling(30).mean()\n",
        "    oil.price.expanding().mean()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "noteable": {
      "last_delta_id": "c4767f68-1617-447f-b6fa-71bde3ba0cc8",
      "last_transaction_id": "c4767f68-1617-447f-b6fa-71bde3ba0cc8"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "42a77478-2b2d-588d-b3ad-1ce8d9aeb4fe",
        "openai_ephemeral_user_id": "5f8354d0-ac01-5600-b432-cd6d5e01c6fc",
        "openai_subdivision1_iso_code": "US-TX"
      }
    },
    "nteract": {
      "version": "noteable@2.9.0"
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
